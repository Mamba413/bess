% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bess.R
\name{bess}
\alias{bess}
\title{Best subset selection}
\usage{
bess(
  x,
  y,
  family = c("gaussian", "binomial", "poisson", "cox"),
  type = c("bss", "bsrr"),
  method = c("gsection", "sequential", "pgsection", "psequential"),
  tune = c("gic", "ebic", "bic", "aic", "cv"),
  s.list,
  lambda.list = 0,
  s.min,
  s.max,
  lambda.min = 0.001,
  lambda.max = 100,
  nlambda = 100,
  screening.num = NULL,
  normalize = NULL,
  weight = NULL,
  max.iter = 20,
  warm.start = TRUE,
  nfolds = 5,
  group.index = NULL
)
}
\arguments{
\item{x}{Input matrix, of dimension n x p; each row is an observation
vector.}

\item{y}{The response variable, of length n. For family="binomial" should be
a factor with two levels. For family= "cox", y should be a two-column matrix
with columns named 'time' and 'status'.}

\item{family}{One of the GLM or Cox models. Either "gaussian", "binomial",
"poisson", or "cox", depending on the response.}

\item{type}{One of the two types of problems. Options are "bss" and "bsrr".}

\item{method}{Methods to be used to select the optimal model size. For
\code{method} = "\code{sequential}", we solve the best subset selection
problem for each \eqn{s} in \eqn{1,2,\dots,s_{max}}. For \code{method} =
"\code{gsection}", which is only valid for method "PDAS" and "GPDAS", we
solve the best subset selection problem with a range non-continuous model
sizes. For \code{method} = "\code{pgsection}" and \code{psequential}, the powell method is used to
solve the "L0L2" problem.}

\item{tune}{The criterion for choosing the sparsity or L_2 penalty
parameters. Available options are "gic", "ebic", "bic", "aic" and "cv".
Default is "GIC".}

\item{s.list}{An increasing list of sequential value representing the model
sizes. Only used for method = "sequential".Default is (1,\eqn{\min{p,
n/\log(n)}}).}

\item{lambda.list}{A lambda sequence for "\code{L0L2}". Default is
\code{exp(seq(log(100), log(0.01), length.out = 100))}.}

\item{s.min}{The minimum value of model sizes. Only used for method =
"\code{gsection}". Default is 1.}

\item{s.max}{The maximum value of model sizes. Only used for method =
"\code{gsection}". Default is \eqn{\min{p, n/\log(n)}}.}

\item{lambda.min}{The minimum value of lambda. Only used for method =
"\code{powell}". Default is 0.01.}

\item{lambda.max}{The maximum value of lambda. Only used for method =
"\code{powell}". Default is 100.}

\item{nlambda}{The number of lambdas for the powell path.}

\item{screening.num}{The number of screening variables.}

\item{normalize}{Options for data mean-substraction or normalization. "0" for
no data process.  Entering "1" will
only substract the mean of columns of X.
2 for scaling the columns of x to have \eqn{\sqrt n} norm.
3 for centralizing the columns of X and y, and also
normalizing the colnums of X to have \eqn{\sqrt n} norm. Entering other number will normalize the
columns of x. If \code{NULL}, \code{normalize} will be "1" for "gaussian",
"2" for "binomial", "3" for "cox".}

\item{weight}{Observation weights. Default is 1 for each observation.}

\item{max.iter}{The maximum number of iterations in the bess function. In
linear regression, only a few steps can guarantee the convergence. Default
is 20.}

\item{warm.start}{Whether to use the last solution as a warm start. Default
is \code{TRUE}.}

\item{nfolds}{The number of folds in cross-validation. Default is 5.}

\item{group.index}{A vector indicating the group index for each variable.}
}
\value{
A list with class attribute 'bess' and named components:
\item{beta}{The best fitting coefficients.} \item{coef0}{The best fitting
intercept.} \item{train_loss}{The training loss of the best fitting model.}
\item{ic}{The information criterion of the best fitting model when model
selection is based on a certain information criterion.} \item{cvm}{The mean
cross-validated error for the best fitting model when model selection is
based on the cross-validation.}

\item{lambda}{the lambda chosen for the best fitting model}
\item{beta_all}{A list of the best fitting coefficients of size
\eqn{s=0,1,\dots,p} and \eqn{\lambda} in \code{lambda.list} with the
smallest loss function. For example, the fitting coefficients of the
\eqn{i^{th} \lambda} and the \eqn{j^{th}} \code{s} is at the \eqn{i^{th}}
list component's \eqn{j^{th}} column.} \item{coef0_all}{The best fitting
intercepts of size \eqn{s=0,1,\dots,p} and \eqn{\lambda} in
\code{lambda.list} with the smallest loss function.} \item{train_loss_all}{A
list of the training loss the best fitting intercepts of model size
\eqn{s=0,1,\dots,p} and \eqn{\lambda} in \code{lambda.list}. For example,
the training loss of the \eqn{i^{th} \lambda} and the \eqn{j^{th}} \code{s}
is at the \eqn{i^{th}} list component's \eqn{j^{th}} entry.} \item{ic_all}{A
matrix of the mean cross-validated error of model size \eqn{s=0,1,\dots,p}
and \eqn{\lambda} in \code{lambda.list} with the smallest loss function. For
example, the training loss of the \eqn{i^{th} \lambda} and the \eqn{j^{th}}
\code{s} is at the \eqn{i^{th}} row \eqn{j^{th}} column. Only available when
model selection is based on a certain information criterion.}

\item{cvm_all}{A matrix of the information criteria of model size
\eqn{s=0,1,\dots,p} and \eqn{\lambda} in \code{lambda.list} with the
smallest loss function. For example, the training loss of the \eqn{i^{th}
\lambda} and the \eqn{j^{th}} \code{s} is at the \eqn{i^{th}} row
\eqn{j^{th}} column. Only available when model selection is based on the
cross-validation.} \item{lambda_all}{The lambda chosen for each step.}
\item{family}{Types of the model: "\code{gaussian}" for linear
model,"\code{binomial}" for logistic model,"\code{poisson}" for poisson
model, and "\code{cox}" for Cox model.} \item{factor}{Which variable to be
factored. Should be NULL or a numeric vector.} \item{s.list}{The input
\code{s.list}.} \item{nsample}{The sample size.} \item{tyoe}{One of the
three algorithm types, "PDAS", "GPDAS", and "L0L2".} \item{method}{One of
the three methods, "sequential", "gsection", and "powell".}
\item{ic_type}{The criterion of model selection. Either "cv", "AIC", "BIC",
"GBIC", or "EBIC".}
}
\description{
Best subset selection for generalized linear model and Cox's proportional
model.
}
\details{
The best subset selection problem with model size \eqn{s} is
\deqn{\min_\beta -2 logL(\beta) \;\;{\rm s.t.}\;\; \|\beta\|_0 \leq s.} In
the GLM case, \eqn{logL(\beta)} is the log-likelihood function; In the Cox
model, \eqn{logL(\beta)} is the log partial likelihood function.

The best ridge regression problem with model size \eqn{s} is
\deqn{\min_\beta -2 logL(\beta) + \lambda\Vert\beta\Vert_2^2 \;\;{\rm
s.t.}\;\; \|\beta\|_0 \leq s.} In the GLM case, \eqn{logL(\beta)} is the
log-likelihood function; In the Cox model, \eqn{logL(\beta)} is the log
partial likelihood function.

For each candidate model size and \eqn{\lambda}, the best subset selection
problem is solved by the primal-dual active set (PDAS) algorithm, see Wen et
al(2017) for details. And the best ridge regression is solved by the
\eqn{L_2} penalized primal-dual active set algorithm. These algorithms
utilize an active set updating strategy via primal and dual variables and
fits the sub-model by exploiting the fact that their support sets are
non-overlap and complementary. For the case of method = "\code{sequential}"
if \code{is_warms_start} = "TRUE", we run the PDAS algorithm for a list of
sequential model sizes and use the estimate from the last iteration as a
warm start. For the case of method = "\code{gsection}" of the best subset
selection problem, a golden section search technique is adopted to
efficiently determine the optimal model size. And for the case of method =
"\code{powell}" of the best ridge regression problem, the powell method is
used for parameters determination, the line search method of which is
sepecified by \code{line_search} = "sequential" or "gsection".
}
\examples{


#-------------------linear model----------------------#
# Generate simulated data
n = 200
p = 20
k = 5
rho = 0.4
SNR = 10
cortype = 1
seed = 10
Data = gen.data(n, p, k, rho, family = "gaussian", cortype = cortype, SNR = SNR, seed = seed)
x = Data$x[1:140, ]
y = Data$y[1:140]
x_new = Data$x[141:200, ]
y_new = Data$y[141:200]
lm.pdas = bess(x, y, method = "sequential")
lambda.list = exp(seq(log(5), log(0.1), length.out = 10))
lm.l0l2 = bess(x, y, type = "bsrr", method = "pgsection")
coef(lm.pdas)
coef(lm.l0l2)
print(lm.pdas)
print(lm.l0l2)
pred.pdas = predict(lm.pdas, newx = x_new)
pred.l0l2 = predict(lm.l0l2, newx = x_new)

# Plot the solution path and the loss function of PDAS
plot(lm.pdas, type = "both", breaks = TRUE)
plot(lm.l0l2)
#-------------------logistic model----------------------#
#Generate simulated data
Data = gen.data(n, p, k, rho, family = "binomial", cortype = cortype, SNR = SNR, seed = seed)

x = Data$x[1:140, ]
y = Data$y[1:140]
x_new = Data$x[141:200, ]
y_new = Data$y[141:200]
logi.pdas = bess(x, y, family = "binomial", method = "sequential", tune = "cv")
lambda.list = exp(seq(log(5), log(0.1), length.out = 10))
logi.l0l2 = bess(x, y, type = "bsrr", tune="cv",
                 family = "binomial", lambda.list = lambda.list, method = "sequential")
coef(logi.pdas)
coef(logi.l0l2)
print(logi.pdas)
print(logi.l0l2)
pred.pdas = predict(logi.pdas, newx = x_new)
pred.l0l2 = predict(logi.l0l2, newx = x_new)

# Plot the solution path and the loss function of PDAS
plot(logi.pdas, type = "both", breaks = TRUE)
#-------------------coxph model----------------------#
#Generate simulated data
Data = gen.data(n, p, k, rho, family = "cox", scal = 10)

x = Data$x[1:140, ]
y = Data$y[1:140, ]
x_new = Data$x[141:200, ]
y_new = Data$y[141:200, ]
cox.pdas = bess(x, y, family = "cox", method = "sequential")
lambda.list = exp(seq(log(5), log(0.1), length.out = 10))
cox.l0l2 = bess(x, y, type = "bsrr", family = "cox", lambda.list = lambda.list)
coef(cox.pdas)
coef(cox.l0l2)
print(cox.pdas)
print(cox.l0l2)
pred.pdas = predict(cox.pdas, newx = x_new)
pred.l0l2 = predict(cox.l0l2, newx = x_new)

# Plot the solution path and the loss function of PDAS
plot(cox.pdas, type = "both", breaks = TRUE)
plot(cox.l0l2)
plot(cox.l0l2)


}
\references{
Wen, C., Zhang, A., Quan, S. and Wang, X. (2020). BeSS: An R
Package for Best Subset Selection in Linear, Logistic and Cox Proportional
Hazards Models, \emph{Journal of Statistical Software}, Vol. 94(4).
doi:10.18637/jss.v094.i04.
}
\seealso{
\code{\link{plot.bess}}, \code{\link{summary.bess}},
\code{\link{coef.bess}}, \code{\link{predict.bess}}.
}
\author{
Liyuan Hu, Aijun Zhang, Shijie Quan, and Xueqin Wang.
}
